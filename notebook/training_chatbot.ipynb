{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "166b74ed",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #e3f2fd; padding: 20px; border-radius: 10px; border-left: 8px solid #2196f3;\"> <h1 style=\"color: #1565c0; margin-bottom: 5px;\">MindSchedule AI: Intent Classification</h1> <p style=\"font-size: 1.2em; color: #455a64;\">Pelatihan Model NLP untuk Manajemen Jadwal & Kesehatan Mental Mahasiswa</p> <hr> <strong>Status Proyek:</strong> Tahap 1 - Pemodelan AI (Offline Training) </div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ba5500",
   "metadata": {},
   "source": [
    "[1] IMPORT LIBRARY\n",
    "\n",
    "Kita memuat library utama. Scikit-learn digunakan untuk ML klasik, dan Datasets dari HuggingFace untuk mengambil data riset terbaru."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c6b230b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚è≥ Menginisialisasi sistem dan library...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\faisa\\anaconda3\\envs\\nlp-chatbot\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Library dan Resource NLTK siap digunakan!\n"
     ]
    }
   ],
   "source": [
    "print(\"‚è≥ Menginisialisasi sistem dan library...\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "import joblib\n",
    "import os\n",
    "from datasets import load_dataset\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Unduh resource pendukung NLTK\n",
    "nltk.download(\"stopwords\", quiet=True)\n",
    "nltk.download(\"wordnet\", quiet=True)\n",
    "nltk.download(\"omw-1.4\", quiet=True)\n",
    "\n",
    "print(\"‚úÖ Library dan Resource NLTK siap digunakan!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e935fb0c",
   "metadata": {},
   "source": [
    "[3] LOAD DATASET DARI HUGGINGFACE\n",
    "\n",
    "Kita menggunakan dua sumber dataset publik untuk memperkaya konteks asisten:\n",
    "\n",
    "Mental Health Dataset: heliosbrahma/mental_health_chatbot_dataset - Berisi percakapan seputar isu kesehatan mental.\n",
    "\n",
    "Student Assistance: bot-remains/student-assistance-chatbot - Berisi dataset bantuan akademik mahasiswa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "069360ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üåê Menghubungkan ke HuggingFace...\n",
      "‚úÖ Berhasil! Mental Health: 172 baris, Student: 217 baris\n",
      "\n",
      "üîç Preview Tabel Mental Health:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;HUMAN&gt;: What is a panic attack?\\n&lt;ASSISTANT&gt;:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;HUMAN&gt;: What are symptoms of panic attack vs....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;HUMAN&gt;: What are the types of Mental Illness?...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  <HUMAN>: What is a panic attack?\\n<ASSISTANT>:...\n",
       "1  <HUMAN>: What are symptoms of panic attack vs....\n",
       "2  <HUMAN>: What are the types of Mental Illness?..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Preview Tabel Student Assistance:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>instruction</th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Greetings and Farewells</td>\n",
       "      <td>Respond to greetings and farewells.</td>\n",
       "      <td>Hi, how are you?</td>\n",
       "      <td>Hello! I'm doing great, thank you. How about you?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Greetings and Farewells</td>\n",
       "      <td>Respond to greetings and farewells.</td>\n",
       "      <td>Goodbye, see you later!</td>\n",
       "      <td>Goodbye! Take care and see you soon!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Greetings and Farewells</td>\n",
       "      <td>Respond to greetings and farewells.</td>\n",
       "      <td>Hi</td>\n",
       "      <td>Hello there! How can I help you today?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  category                          instruction  \\\n",
       "0  Greetings and Farewells  Respond to greetings and farewells.   \n",
       "1  Greetings and Farewells  Respond to greetings and farewells.   \n",
       "2  Greetings and Farewells  Respond to greetings and farewells.   \n",
       "\n",
       "                     input                                             output  \n",
       "0         Hi, how are you?  Hello! I'm doing great, thank you. How about you?  \n",
       "1  Goodbye, see you later!               Goodbye! Take care and see you soon!  \n",
       "2                       Hi             Hello there! How can I help you today?  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"üåê Menghubungkan ke HuggingFace...\")\n",
    "try:\n",
    "    # Load Mental Health\n",
    "    ds_mental = load_dataset(\"heliosbrahma/mental_health_chatbot_dataset\", split=\"train\")\n",
    "    df_mental = pd.DataFrame(ds_mental)\n",
    "\n",
    "    # Load Student Assistance\n",
    "    ds_student = load_dataset(\"bot-remains/student-assistance-chatbot\", split=\"train\")\n",
    "    df_student = pd.DataFrame(ds_student)\n",
    "\n",
    "    print(f\"‚úÖ Berhasil! Mental Health: {len(df_mental)} baris, Student: {len(df_student)} baris\")\n",
    "    \n",
    "    print(\"\\nüîç Preview Tabel Mental Health:\")\n",
    "    display(df_mental.head(3))\n",
    "    \n",
    "    print(\"\\nüîç Preview Tabel Student Assistance:\")\n",
    "    display(df_student.head(3))\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d82dde",
   "metadata": {},
   "source": [
    "üõ†Ô∏è [4] PREPROCESSING & NORMALISASI\n",
    "(Gunakan Markdown Cell) Langkah ini sangat krusial. Kita menyamakan nama kolom dan membersihkan teks dari karakter yang tidak perlu (simbol, angka, kata hubung) agar model lebih fokus pada kata kunci penting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10874727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚è≥ Menyelaraskan kolom dan membersihkan teks...\n",
      "‚úÖ Data Gabungan Siap!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>intent</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mental_health</th>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Course Information</th>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Open-Ended Questions</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>General Questions</th>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Placement Information</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Scholarships</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Apologies</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hostel Facilities</th>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Contact Details</th>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alumni Information</th>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Greetings and Farewells</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Seat Availability</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Previous Years' Cutoff</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ranking Information</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Admission Process</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Eligibility Criteria</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Campus Life</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fee Structure</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Questions and Answers</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         count\n",
       "intent                        \n",
       "mental_health              172\n",
       "Course Information          25\n",
       "Open-Ended Questions        20\n",
       "General Questions           17\n",
       "Placement Information       16\n",
       "Scholarships                16\n",
       "Apologies                   16\n",
       "Hostel Facilities           15\n",
       "Contact Details             15\n",
       "Alumni Information          14\n",
       "Greetings and Farewells     13\n",
       "Seat Availability           12\n",
       "Previous Years' Cutoff       7\n",
       "Ranking Information          6\n",
       "Admission Process            6\n",
       "Eligibility Criteria         6\n",
       "Campus Life                  6\n",
       "Fee Structure                5\n",
       "Questions and Answers        2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"‚è≥ Menyelaraskan kolom dan membersihkan teks...\")\n",
    "\n",
    "# 1. Normalisasi Mental Health\n",
    "# Mencari kolom teks: bisa 'text', 'Context', atau 'Questions'\n",
    "mental_text_col = [c for c in df_mental.columns if c in ['text', 'Context', 'Questions']][0]\n",
    "df_mental = df_mental.rename(columns={mental_text_col: 'text'})\n",
    "df_mental[\"intent\"] = \"mental_health\"\n",
    "\n",
    "# 2. Normalisasi Student Assistance\n",
    "df_student = df_student.rename(columns={\"input\": \"text\", \"category\": \"intent\"})\n",
    "\n",
    "# 3. Gabungkan & Bersihkan\n",
    "df = pd.concat([df_mental[['text', 'intent']], df_student[['text', 'intent']]], ignore_index=True)\n",
    "df = df.dropna(subset=['text']).reset_index(drop=True)\n",
    "\n",
    "# 4. Cleaning Function\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def clean_process(text):\n",
    "    text = re.sub(r\"[^a-z\\s]\", \"\", str(text).lower())\n",
    "    return \" \".join([lemmatizer.lemmatize(w) for w in text.split() if w not in stop_words])\n",
    "\n",
    "df[\"final_text\"] = df[\"text\"].apply(clean_process)\n",
    "\n",
    "print(\"‚úÖ Data Gabungan Siap!\")\n",
    "display(df[\"intent\"].value_counts().to_frame())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37197d6c",
   "metadata": {},
   "source": [
    "üíæ [6] PENYIMPANAN ARTIFAK MODEL\n",
    "(Gunakan Markdown Cell) Tahap terakhir adalah menyimpan model ke folder ../model/. File inilah yang nantinya akan digunakan oleh FastAPI di tahap pengembangan backend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14a9626f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚è≥ Training model sedang berjalan...\n",
      "‚úÖ Training Selesai! Akurasi: 73.08%\n",
      "\n",
      "üìä Laporan Klasifikasi:\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "      Admission Process       0.00      0.00      0.00         1\n",
      "     Alumni Information       1.00      1.00      1.00         3\n",
      "              Apologies       0.00      0.00      0.00         3\n",
      "            Campus Life       0.00      0.00      0.00         1\n",
      "        Contact Details       1.00      1.00      1.00         3\n",
      "     Course Information       0.83      1.00      0.91         5\n",
      "   Eligibility Criteria       0.00      0.00      0.00         1\n",
      "          Fee Structure       0.00      0.00      0.00         1\n",
      "      General Questions       0.00      0.00      0.00         4\n",
      "Greetings and Farewells       1.00      0.33      0.50         3\n",
      "      Hostel Facilities       1.00      0.67      0.80         3\n",
      "   Open-Ended Questions       0.00      0.00      0.00         4\n",
      "  Placement Information       1.00      1.00      1.00         3\n",
      " Previous Years' Cutoff       0.00      0.00      0.00         1\n",
      "    Ranking Information       0.00      0.00      0.00         1\n",
      "           Scholarships       1.00      1.00      1.00         3\n",
      "      Seat Availability       1.00      0.67      0.80         3\n",
      "          mental_health       0.65      1.00      0.79        35\n",
      "\n",
      "               accuracy                           0.73        78\n",
      "              macro avg       0.47      0.43      0.43        78\n",
      "           weighted avg       0.61      0.73      0.65        78\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\faisa\\anaconda3\\envs\\nlp-chatbot\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\faisa\\anaconda3\\envs\\nlp-chatbot\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\faisa\\anaconda3\\envs\\nlp-chatbot\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "print(\"‚è≥ Training model sedang berjalan...\")\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X = vectorizer.fit_transform(df[\"final_text\"])\n",
    "y = df[\"intent\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(f\"‚úÖ Training Selesai! Akurasi: {accuracy_score(y_test, y_pred)*100:.2f}%\")\n",
    "print(\"\\nüìä Laporan Klasifikasi:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60fef7c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚è≥ Menyimpan artifak proyek...\n",
      "\n",
      "========================================\n",
      "üöÄ SELESAI! File berikut telah siap:\n",
      "1. ../model/intent_model.pkl\n",
      "2. ../model/tfidf_vectorizer.pkl\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "print(\"‚è≥ Menyimpan artifak proyek...\")\n",
    "\n",
    "# Buat folder lokal\n",
    "os.makedirs('../model', exist_ok=True)\n",
    "os.makedirs('../data/processed', exist_ok=True)\n",
    "\n",
    "# Simpan .pkl\n",
    "joblib.dump(model, \"../model/intent_model.pkl\")\n",
    "joblib.dump(vectorizer, \"../model/tfidf_vectorizer.pkl\")\n",
    "df.to_csv(\"../data/processed/intents_final.csv\", index=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(\"üöÄ SELESAI! File berikut telah siap:\")\n",
    "print(\"1. ../model/intent_model.pkl\")\n",
    "print(\"2. ../model/tfidf_vectorizer.pkl\")\n",
    "print(\"=\"*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80457c2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßê Mengecek keberadaan file secara fisik...\n",
      "\n",
      "‚úÖ ../model/intent_model.pkl DITEMUKAN!\n",
      "   Ukuran: 397.97 KB\n",
      "‚úÖ ../model/tfidf_vectorizer.pkl DITEMUKAN!\n",
      "   Ukuran: 99.06 KB\n",
      "‚úÖ ../data/processed/intents_final.csv DITEMUKAN!\n",
      "   Ukuran: 347.36 KB\n",
      "\n",
      "üí° Jika 'TIDAK DITEMUKAN', periksa apakah Anda menjalankan notebook dari folder yang benar.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(\"üßê Mengecek keberadaan file secara fisik...\\n\")\n",
    "\n",
    "files = [\"../model/intent_model.pkl\", \"../model/tfidf_vectorizer.pkl\", \"../data/processed/intents_final.csv\"]\n",
    "\n",
    "for f in files:\n",
    "    if os.path.exists(f):\n",
    "        size = os.path.getsize(f) / 1024  # Ukuran dalam KB\n",
    "        print(f\"‚úÖ {f} DITEMUKAN!\")\n",
    "        print(f\"   Ukuran: {size:.2f} KB\")\n",
    "    else:\n",
    "        print(f\"‚ùå {f} TIDAK DITEMUKAN!\")\n",
    "\n",
    "print(\"\\nüí° Jika 'TIDAK DITEMUKAN', periksa apakah Anda menjalankan notebook dari folder yang benar.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-chatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
